{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import operator\n",
    "import time\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import implicit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the matrix\n",
    "def load_matrix(filepath, num_users, num_items):\n",
    "    counts = np.zeros((num_users, num_items))\n",
    "    for i, line in enumerate(open(filepath, 'r')):\n",
    "        user, item, count = line.strip().split(',')\n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "        count = float(count)\n",
    "        counts[user][item] = count\n",
    "    return counts\n",
    "\n",
    "def sparser(originalmatrix, num_users, num_items):\n",
    "    counts = sparse.dok_matrix((num_users, num_items), dtype=float)\n",
    "    for i in range(len(originalmatrix)):\n",
    "        row = originalmatrix[i]\n",
    "        for j in range(len(row)):\n",
    "            if row[j] > 0:\n",
    "                user = int(i)\n",
    "                item = int(j)\n",
    "                count = float(row[j])\n",
    "                counts[user, item] = count\n",
    "    counts = counts.tocsr()\n",
    "    return counts\n",
    "\n",
    "#Please enter the path to the input data\n",
    "filepath = 'C:/Users/peter/Documents/uvt/implicit/finalxdata.csv'\n",
    "matrix = load_matrix(filepath, num_users = 6518, num_items = 4036)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions for the hiding of the user-item interactions for the validation and test set\n",
    "def interactiontodrop(rownumber, row): \n",
    "    scoreditems = []\n",
    "    items = dict(enumerate(row))\n",
    "    for k in items:\n",
    "        if items[k] > 0:\n",
    "            scoreditems.append(k)\n",
    "    random.seed(1)\n",
    "    if not scoreditems:\n",
    "        print(rownumber)\n",
    "    return [rownumber, random.choice(scoreditems)]\n",
    "\n",
    "\n",
    "def dropper(matrix, n):\n",
    "    r = list(range(len(matrix)))\n",
    "    random.seed(1)\n",
    "    sample = random.sample(r,n)\n",
    "    toodrop = []\n",
    "    for x in sample:\n",
    "        toodrop.append(interactiontodrop(x, matrix[x]))\n",
    "    for item in toodrop:\n",
    "        matrix[item[0]][item[1]] = 0\n",
    "    return toodrop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating the test set\n",
    "test_set = dropper(matrix, 650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for the evaluation\n",
    "def prediction(userid, similarities, matrix, originalmatrix, n=4036):\n",
    "    predictions = np.dot(matrix[userid], similarities)\n",
    "    predictions = predictions.toarray()\n",
    "    predictions = predictions[0]\n",
    "    for i in range(4036):\n",
    "        if originalmatrix[userid][i] > 0:\n",
    "            predictions[i] = -6000        \n",
    "    dict = {key: value for (key, value) in (enumerate(predictions))}\n",
    "    sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    recommendation = []\n",
    "    for i in range(n):\n",
    "        recommendation.append(sorted_dict[i][0])\n",
    "    return recommendation\n",
    "\n",
    "\n",
    "def hlu_calc(dropped_items, coefficients, originalmatrix):\n",
    "    model_hlus = []\n",
    "    matrix, similarities = coefficients\n",
    "    for b in dropped_items:\n",
    "        ranking = (prediction(b[0], similarities, matrix, originalmatrix).index(b[1])+1)\n",
    "        if ranking < 250:\n",
    "            ind_hlu = 1 / (2 ** ((ranking) / 10))\n",
    "            model_hlus.append(ind_hlu)\n",
    "        else:\n",
    "            model_hlus.append(0.0000000001)\n",
    "    return model_hlus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Building the model\n",
    "sparsematrix = sparser(matrix.T, 4036, 6518)\n",
    "model = implicit.nearest_neighbours.CosineRecommender(K=20)\n",
    "model.fit(sparsematrix)\n",
    "coefficients = [sparsematrix.T, model.similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models hlu is 0.2847465711886884\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on the test set\n",
    "model_hlus = hlu_calc(test_set, coefficients, matrix)\n",
    "print(\"The models hlu is {}\".format(np.average(model_hlus)))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
