{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pip install implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING AND EVALUATING A RECOMMENDER SYSTEM\n",
    "\n",
    "This Jupyter Notebook explains how an error metric is generated for weighted matrix factorization. It will go through the data manipulation, splitting of the files, implementation of the different RS algorithms and the evaluation of these algorithms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import operator\n",
    "import time\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Please enter the path to the input data\n",
    "#Other input data should look like:\n",
    "#0,1,3\n",
    "#0,2,6\n",
    "#.....\n",
    "#Where 0 is the user, 1 and 2 are items, and 3 and 6 are implicit feedback scores\n",
    "#NOTE: Since this is python, the first item and user should both be labeled 0\n",
    "\n",
    "filepath = 'C:/Users/peter/Documents/uvt/implicit/finalxdata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_matrix(filepath, num_users, num_items):\n",
    "    counts = np.zeros((num_users, num_items))\n",
    "    for i, line in enumerate(open(filepath, 'r')):\n",
    "        user, item, count = line.strip().split(',')\n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "        count = float(count)\n",
    "        counts[user][item] = count\n",
    "    return counts\n",
    "\n",
    "# So what happens here?\n",
    "# The formula creates an empty matrix (counts), of size U by I. \n",
    "# Then it starts stripping each row of the input file, where it extracts the user, item and feedback score.\n",
    "# These values are then used to fill the empty matrix with the implicit feedback score.\n",
    "# Finally it returns the matrix R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix1 = load_matrix(filepath, num_users = 6518, num_items = 4036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have loaded the matrix. Let's look at the row of a random user to get a feeling for the data (for this example we'll use user 100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690 2.0\n",
      "1244 2.0\n",
      "1833 2.0\n",
      "1882 3.0\n",
      "1911 2.0\n",
      "1929 2.0\n",
      "1941 2.0\n",
      "2774 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix1[99]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this user bought 7 different items 2 times, and 1 item 3 times. The code only prints the items on which the user has a purchase record, which means that the user did not purchase the other 4029 items. For good measure, let's look at user 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 2.0\n",
      "1592 2.0\n",
      "1806 2.0\n",
      "1821 2.0\n",
      "1870 2.0\n",
      "1931 2.0\n",
      "2070 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix1[199]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is ready, so lets create a train and test set. First, we'll need to select the users of whom we'll forget one interaction. The following function drops one value in a users row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function tells selects a random user-item-interactions that can be dropped.\n",
    "# Its input is the user's ID, and the user's implicit scores on all items.\n",
    "# It returns a list of the user ID, and the ID of the item that will be dropped by another function.\n",
    "def interactiontodrop(rownumber, row): #rownumber=userid, row=score vector\n",
    "    scoreditems = []\n",
    "    items = dict(enumerate(row))\n",
    "    for k in items:\n",
    "        if items[k] > 0:\n",
    "            scoreditems.append(k)\n",
    "    random.seed(1)\n",
    "    if not scoreditems:\n",
    "        print(rownumber)\n",
    "    return [rownumber, random.choice(scoreditems)]\n",
    "\n",
    "# This function 'drops' the interactions from the matrix (drop means set equal to zero).\n",
    "# It lists all users, and then collects a sample of these users.\n",
    "# For each of these users a random item is selected by the interactiontodrop-function, whereafter it is dropped.\n",
    "# The input is a matrix, and the output is the list of user-item-interactions that are dropped,\n",
    "# this list contains the values that are dropped by this function.\n",
    "def dropper(matrix, n):\n",
    "    r = list(range(len(matrix)))\n",
    "    random.seed(1)\n",
    "    sample = random.sample(r,n)\n",
    "    toodrop = []\n",
    "    for x in sample:\n",
    "        toodrop.append(interactiontodrop(x, matrix[x]))\n",
    "    for item in toodrop:\n",
    "        matrix[item[0]][item[1]] = 0\n",
    "    return toodrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [2, 1], [1, 0]]\n",
      "[[0, 0, 0, 1], [0, 0, 8, 8], [9, 0, 9, 9]]\n"
     ]
    }
   ],
   "source": [
    "# So let's check the functions, consider the following matrix X with three users, and four items.\n",
    "X = [[1,0,0,1],\n",
    "     [8,0,8,8],\n",
    "     [9,9,9,9]]\n",
    "\n",
    "# If we apply the dropper-function to this matrix, it will drop one value in each row, and replace it with zero,\n",
    "# furthermore, it will remember the user and item id of the dropped interactions\n",
    "\n",
    "print(dropper(X, 3))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this example, we have dropped an interaction in each row, namely interaction [0,0], [2,1] and [1,0]\n",
    "the original matrix X is now \n",
    "    X = [[0,0,0,1],\n",
    "         [0,0,8,8],\n",
    "         [9,0,9,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dropper formula we can create the test set, which usually has the size of 20% of the data,\n",
    "or in our case 20% of the 6518 users. Therefore, we call the dropper function on the input data with an N of 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1100, 922], [4662, 3496], [6256, 3905], [516, 1893], [2089, 2891], [965, 230], [4058, 3373], [6233, 3145], [3682, 3388], [3868, 3321]]\n",
      "4662 3496 0.0\n"
     ]
    }
   ],
   "source": [
    "test_set = dropper(matrix1, 650)\n",
    "# So the test set is now ready and the first 10 user-item interactions in the test set are:\n",
    "print(test_set[0:10])\n",
    "# The values of these items and users are now zero in the original matrix\n",
    "test_user, test_item = test_set[1]\n",
    "print('the implicit feedback value of the first user in the test set, is now zero')\n",
    "print(test_user, test_item, matrix1[test_user][test_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test set ready, we can now train on the training data and generate recommendations!\n",
    "The code below fits a WMF model to the data\n",
    "BTW, don't mind the function below, it is an artifact of my old thesis and I will develop a new error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In order to evaluate our model we need to generate predictions for a user.\n",
    "# We generate predictions by multiplying the item and user vectors and then sort the items based on.\n",
    "def prediction(userid, user_vectors, item_vectors, originalmatrix, n=4036):\n",
    "    # The next line generates the score for a single user.\n",
    "    predictions = np.dot(user_vectors[userid], item_vectors.T)\n",
    "    # Since there are also predictions for items the user DID interact with, we need to set these items to zero.\n",
    "    # (of course these will score highly, since they have positive values in the original matrix)\n",
    "    for i in range(4036):\n",
    "        if originalmatrix[userid][i] > 0:\n",
    "            predictions[i] = -6000\n",
    "    # Sort all items based on the score, and keep the sorted list of item-ids.         \n",
    "    dict = {key: value for (key, value) in (enumerate(predictions))}\n",
    "    sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    recommendation = []\n",
    "    for i in range(n):\n",
    "        recommendation.append(sorted_dict[i][0])\n",
    "    return recommendation\n",
    "\n",
    "def mpr_calc(dropped_items, user_vectors, item_vectors, originalmatrix):\n",
    "    percentile_rankings = []\n",
    "    # dropped item=test set\n",
    "    # So for each user,item in the test set, generate the list for a user, locate the rank of an item (index(b[1]),\n",
    "    # and then divide by the total number of items.\n",
    "    # Finally store the ranking of this user in a list for all users.\n",
    "    for b in dropped_items:\n",
    "        percentile_ranking = (prediction(b[0], user_vectors, item_vectors, originalmatrix).index(b[1]) + 1) / ((4036))\n",
    "        percentile_rankings.append(percentile_ranking)\n",
    "    return percentile_rankings\n",
    "\n",
    "def hlu_calc(dropped_items, user_vectors, item_vectors, originalmatrix):\n",
    "    all_hlu = []\n",
    "    for b in dropped_items:\n",
    "        ranking = prediction(b[0], user_vectors, item_vectors, originalmatrix).index(b[1]) + 1\n",
    "        individual_hlu = 1/(2**((ranking+1)/10))\n",
    "        all_hlu.append(individual_hlu)\n",
    "    return all_hlu\n",
    "\n",
    "def sparser(originalmatrix, num_users, num_items):\n",
    "    counts = sparse.dok_matrix((num_users, num_items), dtype=float)\n",
    "    for i in range(len(originalmatrix)):\n",
    "        row = originalmatrix[i]\n",
    "        for j in range(len(row)):\n",
    "            if row[j] > 0:\n",
    "                user = int(i)\n",
    "                item = int(j)\n",
    "                count = float(row[j])\n",
    "                counts[user, item] = count\n",
    "    counts = counts.tocsr()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0860109018831\n"
     ]
    }
   ],
   "source": [
    "matrix1 = matrix1*10\n",
    "flipped = matrix1.T\n",
    "sparsematrix = sparser(flipped, 4036, 6518)\n",
    "wmf = implicit.als.AlternatingLeastSquares(factors=40, regularization=0.1, iterations=20)\n",
    "wmf.fit(sparsematrix)\n",
    "print(np.average(mpr_calc(test_set, (wmf.user_factors), (wmf.item_factors), matrix1)))\n",
    "print(np.average(hlu_calc(test_set, (wmf.user_factors), (wmf.item_factors), matrix1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error metric calculation is now done. Below are some small things that I wanted to show. The first box will print the the user and item factors, while the second box shows how we can compute recommendations with these factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.02445708 -0.75462322  0.51603423  0.39406674  0.06896798 -0.38594222\n",
      " -0.36607757  1.2692164   0.33990333  0.01336935  1.64384154  0.44549519\n",
      " -0.38010104  0.32407807  0.05395025  0.12491241  0.56813029  1.3735044\n",
      "  0.60461521  0.42391448  0.92220032  0.57576944  0.39123932 -0.83277707\n",
      "  1.06618653 -0.07535544 -0.39173272  0.40998265 -0.10037952  0.56932853\n",
      " -1.34936214  0.00838501  0.45339072 -1.82116499 -1.11187079 -0.50163748\n",
      "  0.5305226   0.12710697  0.38954433 -0.57443069]\n",
      "[ 0.01765419  0.04446135 -0.03864371 -0.00268694  0.01044716  0.00210448\n",
      " -0.00953599  0.00906902  0.00620778 -0.00671141  0.05174084  0.03203721\n",
      "  0.00553551 -0.0342268   0.01280689 -0.01784982 -0.00429016 -0.02965901\n",
      " -0.02506625  0.02072554 -0.0559107  -0.02168349 -0.00534054  0.01673514\n",
      "  0.02664424  0.00927827 -0.02705793 -0.02476204 -0.0138883  -0.00703672\n",
      " -0.00802228  0.01938651  0.02338761 -0.01892339  0.02653332  0.01756498\n",
      "  0.0052419   0.00820092  0.03683066  0.00417348]\n"
     ]
    }
   ],
   "source": [
    "print(wmf.user_factors[1])\n",
    "print(wmf.item_factors[1])\n",
    "# Notice that these values are low, which means that the regularization is doing its job well! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the example below, were we have user 2, and items 1, 2, and 3, we can see the computed scores for user 1. As we can see, the user has the highest score on item 2, so we would recommend this item to this user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0202808522469\n",
      "-0.00550191601516\n",
      "0.0677161486725\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(wmf.item_factors[0],wmf.user_factors[1]))\n",
    "print(np.dot(wmf.item_factors[1],wmf.user_factors[1]))\n",
    "print(np.dot(wmf.item_factors[2],wmf.user_factors[1])) #<-- the highest score"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
