{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### pip install implicit\n",
    "\n",
    "use this command in the anaconda prompt before executing this notebook, since this notebook uses the implicit.py package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING AND EVALUATING A RECOMMENDER SYSTEM (RS)\n",
    "\n",
    "This Jupyter Notebook explains how an error metric is generated for weighted matrix factorization. It will go through the data manipulation, splitting of the files, implementation of the WMF RS algorithm and the RS's evaluation process.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#installing packages\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.sparse as sparse\n",
    "import operator\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Please enter the path to the input data\n",
    "#Other input data should look like:\n",
    "#0,1,3\n",
    "#0,2,6\n",
    "#.....\n",
    "#Where 0 is the user, 1 and 2 are items, and 3 and 6 are implicit feedback scores\n",
    "#NOTE: Since this is python, the first item and user should both be labeled 0\n",
    "\n",
    "filepath = 'C:/Users/peter/Documents/uvt/implicit/finalxdata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_matrix(filepath, num_users, num_items):\n",
    "    counts = np.zeros((num_users, num_items))\n",
    "    for i, line in enumerate(open(filepath, 'r')):\n",
    "        user, item, count = line.strip().split(',')\n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "        count = float(count)\n",
    "        counts[user][item] = count\n",
    "    return counts\n",
    "\n",
    "# So what happens here?\n",
    "# The formula creates an empty matrix (counts), of size U by I. \n",
    "# Then it starts stripping each row of the input file, where it extracts the user, item and feedback score.\n",
    "# These values are then used to fill the empty matrix with the implicit feedback score.\n",
    "# Finally it returns the matrix R.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix = load_matrix(filepath, num_users = 6518, num_items = 4036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have loaded the matrix. Let's look at the row of a random user to get a feeling for the data (for this example we'll use user 100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690 2.0\n",
      "1244 2.0\n",
      "1833 2.0\n",
      "1882 3.0\n",
      "1911 2.0\n",
      "1929 2.0\n",
      "1941 2.0\n",
      "2774 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix[99]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this user bought 7 different items 2 times, and 1 item 3 times. The code only prints the items on which the user has a purchase record, which means that the user did not purchase the other 4029 items. For good measure, let's look at user 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 2.0\n",
      "1592 2.0\n",
      "1806 2.0\n",
      "1821 2.0\n",
      "1870 2.0\n",
      "1931 2.0\n",
      "2070 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix[199]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is ready, so lets create a train and test set. First, we'll need to select the users of whom we'll hide one interaction. The following function drops one value in a users row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function tells selects a random user-item-interactions that can be dropped.\n",
    "# Its input is the user's ID, and the user's implicit scores on all items.\n",
    "# It returns a list of the user ID, and the ID of the item that will be dropped by another function.\n",
    "def interactiontodrop(rownumber, row): #rownumber=userid, row=score vector\n",
    "    scoreditems = []\n",
    "    items = dict(enumerate(row))\n",
    "    for k in items:\n",
    "        if items[k] > 0:\n",
    "            scoreditems.append(k)\n",
    "    random.seed(1)\n",
    "    if not scoreditems:\n",
    "        print(rownumber)\n",
    "    return [rownumber, random.choice(scoreditems)]\n",
    "\n",
    "# This function 'drops' the interactions from the matrix (drop means set equal to zero).\n",
    "# It lists all users, and then collects a sample of these users.\n",
    "# For each of these users a random item is selected by the interactiontodrop-function, whereafter it is dropped.\n",
    "# The input is a matrix, and the output is the list of user-item-interactions that are dropped,\n",
    "# this list contains the values that are dropped by this function.\n",
    "def dropper(matrix, n):\n",
    "    r = list(range(len(matrix)))\n",
    "    random.seed(1)\n",
    "    sample = random.sample(r,n)\n",
    "    toodrop = []\n",
    "    for x in sample:\n",
    "        toodrop.append(interactiontodrop(x, matrix[x]))\n",
    "    for item in toodrop:\n",
    "        matrix[item[0]][item[1]] = 0\n",
    "    return toodrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [2, 1], [1, 0]]\n",
      "[[0, 0, 0, 1], [0, 0, 8, 8], [9, 0, 9, 9]]\n"
     ]
    }
   ],
   "source": [
    "# So let's check the functions, consider the following matrix X with three users, and four items.\n",
    "X = [[1,0,0,1],\n",
    "     [8,0,8,8],\n",
    "     [9,9,9,9]]\n",
    "\n",
    "# If we apply the dropper-function to this matrix, it will drop one value in each row, and replace it with zero,\n",
    "# furthermore, it will remember the user and item id of the dropped interactions\n",
    "\n",
    "print(dropper(X, 3))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this example, we have dropped an interaction in each row, namely interaction [0,0], [2,1] and [1,0]\n",
    "the original matrix X is now \n",
    "    X = [[0,0,0,1],\n",
    "         [0,0,8,8],\n",
    "         [9,0,9,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dropper formula we can create the test set, which usually has the size of 20% of the data,\n",
    "or in our case 20% of the 6518 users. Therefore, we call the dropper function on the input data with an N of 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1100, 590], [4662, 3351], [6256, 3907], [516, 615], [2089, 1817], [965, 449], [4058, 3394], [6233, 3485], [3682, 3417], [3868, 3376]]\n",
      "the implicit feedback value of the first user in the test set, is now zero\n",
      "4662 3351 0.0\n"
     ]
    }
   ],
   "source": [
    "test_set = dropper(matrix, 650)\n",
    "# So the test set is now ready and the first 10 user-item interactions in the test set are:\n",
    "print(test_set[0:10])\n",
    "# The values of these items and users are now zero in the original matrix\n",
    "test_user, test_item = test_set[1]\n",
    "print('the implicit feedback value of the first user in the test set, is now zero')\n",
    "print(test_user, test_item, matrix[test_user][test_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test set ready, we can now train on the training data and generate recommendations!\n",
    "The code below fits a WMF model to the data and then calculates the MPR and HLU of this recommendation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and evaluating the RS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In order to evaluate our model we need to generate predictions for a user.\n",
    "# We generate predictions by multiplying the item and user vectors and then sort the items based on.\n",
    "def prediction(userid, user_vectors, item_vectors, originalmatrix, n=4036):\n",
    "    # The next line generates the score for a single user.\n",
    "    predictions = np.dot(user_vectors[userid], item_vectors.T)\n",
    "    # Since there are also predictions for items the user DID interact with, we need to set these items to zero.\n",
    "    # (of course these will score highly, since they have positive values in the original matrix)\n",
    "    for i in range(4036):\n",
    "        if originalmatrix[userid][i] > 0:\n",
    "            predictions[i] = -6000\n",
    "    # Sort all items based on the score, and keep the sorted list of item-ids.         \n",
    "    dict = {key: value for (key, value) in (enumerate(predictions))}\n",
    "    sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    recommendation = []\n",
    "    for i in range(n):\n",
    "        recommendation.append(sorted_dict[i][0])\n",
    "    return recommendation\n",
    "\n",
    "def hlu_calc(dropped_items, coefficients, originalmatrix):\n",
    "    exceptions=0\n",
    "    model_hlus = []\n",
    "    user_vectors, item_vectors = coefficients\n",
    "    for b in dropped_items:\n",
    "        ranking = (prediction(b[0], user_vectors, item_vectors, originalmatrix).index(b[1]) + 1)\n",
    "        if ranking < 250:\n",
    "            ind_hlu = 1 / (2 ** ((ranking) / 10))\n",
    "            model_hlus.append(ind_hlu)\n",
    "        else:\n",
    "            model_hlus.append(0.0000000001)\n",
    "    return model_hlus\n",
    "\n",
    "def sparser(originalmatrix, num_users, num_items):\n",
    "    counts = sparse.dok_matrix((num_users, num_items), dtype=float)\n",
    "    for i in range(len(originalmatrix)):\n",
    "        row = originalmatrix[i]\n",
    "        for j in range(len(row)):\n",
    "            if row[j] > 0:\n",
    "                user = int(i)\n",
    "                item = int(j)\n",
    "                count = float(row[j])\n",
    "                counts[user, item] = count\n",
    "    counts = counts.tocsr()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287341019224\n"
     ]
    }
   ],
   "source": [
    "alpha = 10\n",
    "matrix = matrix*alpha\n",
    "originalmatrix = matrix\n",
    "sparsematrix = sparser(matrix.T,  4036, 6518)\n",
    "\n",
    "lambdaa = 100\n",
    "model = implicit.als.AlternatingLeastSquares(factors=40, regularization=lambdaa, iterations=20)\n",
    "model.fit(sparsematrix)\n",
    "coefficients = [model.user_factors, model.item_factors]\n",
    "print(np.average(hlu_calc(test_set, coefficients, originalmatrix)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error metric calculation is now done. Below are some small things that I wanted to show. The first box will print the the user and item factors, while the second box shows how we can compute recommendations with these factors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08465731  0.17181078 -0.00510556  0.04716576  0.04517242 -0.17156409\n",
      " -0.00533178  0.15251428  0.02906568 -0.03172248 -0.13372508  0.12144216\n",
      "  0.1056866  -0.14930712  0.05187108 -0.00961629  0.02596432  0.09711035\n",
      " -0.05205087 -0.0819291   0.01326078  0.03573604 -0.05354777 -0.11622727\n",
      " -0.02600523 -0.04785348  0.12724786  0.02505602  0.13189727  0.00894016\n",
      "  0.07240166  0.07903485  0.1500971  -0.03712733 -0.02099241  0.06957538\n",
      "  0.16389345  0.10668174 -0.04928369 -0.04644141]\n",
      "[ 0.15259294  0.02953436 -0.28032857  0.28797397 -0.05375853  0.20113707\n",
      " -0.07640658  0.03272772  0.19296071  0.0330456  -0.13341269 -0.08293246\n",
      " -0.05825168  0.02409248  0.10360389  0.02094175  0.201208   -0.09912423\n",
      "  0.09220193 -0.15053514 -0.17906176  0.08305001 -0.01685078 -0.03537828\n",
      "  0.20889714  0.05562918 -0.19676389  0.00037664  0.06571762  0.11021221\n",
      "  0.03945126 -0.01053052 -0.0167024   0.22189032 -0.08333427 -0.06168398\n",
      "  0.00448949 -0.04210619  0.04932621 -0.23123421]\n"
     ]
    }
   ],
   "source": [
    "print(model.user_factors[1])\n",
    "print(model.item_factors[1])\n",
    "# Notice that these values are low, which means that the regularization is doing its job well! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the example below, were we have user 1, and items 1, 2, and 3, we can see the computed scores for user 1. If we can only recommend 3 items to the user, we would recommend item 2. The user has the highest predicted preference for item 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1 has a score of 0.0038444444071501493\n",
      "Item 2 has a score of 0.017303235828876495\n",
      "Item 3 has a score of -0.015008076094090939\n"
     ]
    }
   ],
   "source": [
    "# something goes wrong here, I don't know what. \n",
    "# When I initially wrote this notebook, item 2 had the highest score, but later item 3 had the highest score.\n",
    "# Something probably goes wrong with the seeding here, but it's not that important.\n",
    "# Just remember, the highest score gets recommended!\n",
    "print(\"Item 1 has a score of {}\".format(np.dot(model.item_factors[0],model.user_factors[0])))\n",
    "print(\"Item 2 has a score of {}\".format(np.dot(model.item_factors[1],model.user_factors[0])))\n",
    "print(\"Item 3 has a score of {}\".format(np.dot(model.item_factors[2],model.user_factors[0]))) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
