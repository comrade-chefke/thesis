{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pip install implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING AND EVALUATING A RECOMMENDER SYSTEM\n",
    "\n",
    "This Jupyter Notebook explains how a error metric is generated for weighted matrix factorization. It will go through the data manipulation, splitting of the files, implementation of the different RS algorithms and the evaluation of these algorithms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import operator\n",
    "import time\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Please enter the path to the input data, which is available to download on XXXXXXXXXXXXX.\n",
    "#Other input data should look like:\n",
    "#0,1,3\n",
    "#0,2,6\n",
    "#.....\n",
    "#where 0 is the user, 1 and 2 are items, and 3 and 6 are implicit feedback scores\n",
    "#NOTE: Since this is python, the first item and user should both be labeled 0\n",
    "\n",
    "filepath = 'C:/Users/peter/Documents/uvt/implicit/finalxdata.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_matrix(filepath, num_users, num_items):\n",
    "    counts = np.zeros((num_users, num_items))\n",
    "    for i, line in enumerate(open(filepath, 'r')):\n",
    "        user, item, count = line.strip().split(',')\n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "        count = float(count)\n",
    "        counts[user][item] = count\n",
    "    return counts\n",
    "\n",
    "# So what happens here?\n",
    "# The formula creates an empty matrix (counts), of size U by I. \n",
    "# Then it starts stripping each row of the input file, where it extracts the user, item and feedback score.\n",
    "# These values are then used to fill the empty matrix with the implicit feedback score.\n",
    "# Finally it returns the matrix R. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-01537e3f3755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6518\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4036\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "matrix1 = load_matrix(filepath, num_users = 6518, num_items = 4036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have loaded the matrix. Let's look at the row of a random user to get a feeling for the data(for this example we'll use user 100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690 2.0\n",
      "1244 2.0\n",
      "1833 2.0\n",
      "1882 3.0\n",
      "1911 2.0\n",
      "1929 2.0\n",
      "1941 2.0\n",
      "2774 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix1[99]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this user bought 7 different items 2 times, and 1 item 3 times. The code only prints the items on which the user has a purchase record, which means that the user did not purchase the other 4029 items. For good measure, let's look at user 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 2.0\n",
      "1592 2.0\n",
      "1806 2.0\n",
      "1821 2.0\n",
      "1870 2.0\n",
      "1931 2.0\n",
      "2070 2.0\n"
     ]
    }
   ],
   "source": [
    "item=0\n",
    "for value in matrix1[199]:\n",
    "    if value>0:\n",
    "        print(item, value)\n",
    "    item+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is ready, so lets get the train and test set in order. First, we'll need to select the users of which we will forget one interaction. The following function drops one value in a users row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function tells selects a random user-item-interactions that can be dropped\n",
    "# its input is the users ID, and a user's implicit scores on all items\n",
    "# it returns a list of the user ID, and the ID of the item that will be dropped by another function\n",
    "def interactiontodrop(rownumber, row):\n",
    "    scoreditems = []\n",
    "    items = dict(enumerate(row))\n",
    "    for k in items:\n",
    "        if items[k] > 0:\n",
    "            scoreditems.append(k)\n",
    "    random.seed(1)\n",
    "    if not scoreditems:\n",
    "        print(rownumber)\n",
    "    return [rownumber, random.choice(scoreditems)]\n",
    "\n",
    "# this function 'drops' the interactions from the matrix (drop means set equal to zero)\n",
    "# it checks which items can be dropped via the morethanx-function (currently all items pass the morethanx-function)\n",
    "# it lists all users for whom items can be dropped, and then collects a sample of these users\n",
    "# for each of these users a random item is selected by the interactiontodrop-function, whereafter it is dropped\n",
    "# the input is a matrix, and the output is the list of user-item-interactions that are dropped,\n",
    "# this list contains the values that are dropped by this function\n",
    "def dropper(matrix, n):\n",
    "    r = list(range(len(matrix)))\n",
    "    random.seed(1)\n",
    "    sample = random.sample(r,n)\n",
    "    toodrop = []\n",
    "    for x in sample:\n",
    "        toodrop.append(interactiontodrop(x, matrix[x]))\n",
    "    for item in toodrop:\n",
    "        matrix[item[0]][item[1]] = 0\n",
    "    return toodrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [2, 1], [1, 0]]\n",
      "[[0, 0, 0, 1], [0, 0, 8, 8], [9, 0, 9, 9]]\n"
     ]
    }
   ],
   "source": [
    "# so let's check the functions, consider the following matrix X with three users, and four items.\n",
    "X = [[1,0,0,1],\n",
    "     [8,0,8,8],\n",
    "     [9,9,9,9]]\n",
    "\n",
    "# if we apply the dropper-function to this matrix, it will drop one value in each row, and replace it with zero,\n",
    "# furthermore, it will remember the user and item id of the dropped interactions\n",
    "\n",
    "print(dropper(X, 3))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this example, we have dropped an interaction in each row, namely interaction [0,0], [2,1] and [1,0]\n",
    "the original matrix X is now \n",
    "    X = [[0,0,0,1],\n",
    "         [0,0,8,8],\n",
    "         [9,0,9,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dropper formula we can create the test set, which usually has the size of 20% of the data,\n",
    "or in our case 20% of the 6518 users. Therefore, we call the dropper function on the input data with an N of 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1100, 590], [4662, 3351], [6256, 3907], [516, 615], [2089, 1817], [965, 449], [4058, 3394], [6233, 3485], [3682, 3417], [3868, 3376]]\n"
     ]
    }
   ],
   "source": [
    "test_set = dropper(matrix1, 650)\n",
    "# so the test set is now ready\n",
    "# and the first 10 user-item interactions in the test set are:\n",
    "print(test_set[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the test set in place, we can now train on the training data and generate recommendations\n",
    "the code below fits a WMF model to the data\n",
    "BTW, don't mind the function below, it is an artifact of my old thesis and I will develop a new error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in order to evaluate our model we need to generate predictions for a user\n",
    "# we generate predictions by multiplying the item and user vectors and then sort the items based on \n",
    "def prediction(userid, user_vectors, item_vectors, originalmatrix, n=4036):\n",
    "    # the next line generates the score for a single user\n",
    "    predictions = np.dot(user_vectors[userid], item_vectors.T)\n",
    "    # since there are also predictions for items the user DID interact with, we need to set these items to zero\n",
    "    # (of course these will score highly, since they have positive values in the original matrix)\n",
    "    for i in range(4036):\n",
    "        if originalmatrix[userid][i] > 0:\n",
    "            predictions[i] = -6000\n",
    "    #sort all items based on the score, and keep the sorted list of item-ids         \n",
    "    dict = {key: value for (key, value) in (enumerate(predictions))}\n",
    "    sorted_dict = sorted(dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    recommendation = []\n",
    "    for i in range(n):\n",
    "        recommendation.append(sorted_dict[i][0])\n",
    "    return recommendation\n",
    "\n",
    "def mpr_calc(dropped_items, user_vectors, item_vectors, originalmatrix):\n",
    "    percentile_rankings = []\n",
    "    #dropped item=test set\n",
    "    #so for each user,item in the test set, generate the list for a user, locate the rank of an item (index(b[1]),\n",
    "    #and then divide by the total number of items\n",
    "    #finally store the ranking of this user in a list for all users\n",
    "    for b in dropped_items:\n",
    "        percentile_ranking = (prediction(b[0], user_vectors, item_vectors, originalmatrix).index(b[1]) + 1) / ((4036))\n",
    "        percentile_rankings.append(percentile_ranking)\n",
    "    return percentile_rankings\n",
    "\n",
    "def sparser(originalmatrix, num_users, num_items):\n",
    "    counts = sparse.dok_matrix((num_users, num_items), dtype=float)\n",
    "    for i in range(len(originalmatrix)):\n",
    "        row = originalmatrix[i]\n",
    "        for j in range(len(row)):\n",
    "            if row[j] > 0:\n",
    "                user = int(i)\n",
    "                item = int(j)\n",
    "                count = float(row[j])\n",
    "                counts[user, item] = count\n",
    "    counts = counts.tocsr()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f74bba746c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mflipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msparsematrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflipped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4036\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6518\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlternatingLeastSquares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparsematrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix1' is not defined"
     ]
    }
   ],
   "source": [
    "matrix1 = matrix1*10\n",
    "flipped = matrix1.T\n",
    "sparsematrix = sparser(flipped, 4036, 6518)\n",
    "wmf = implicit.als.AlternatingLeastSquares(factors=40, regularization=0.1, iterations=20)\n",
    "wmf.fit(sparsematrix)\n",
    "print(np.average(mpr_calc(test_set, (wmf.user_factors), (wmf.item_factors), matrix1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75792477  0.83794315 -0.0441155   0.34144654  0.51893739 -0.0523536\n",
      "  0.81810346 -0.08802933  0.7729655   0.55795031  0.30823591 -0.23916485\n",
      " -0.10338848  0.65232634 -0.11711397  0.71190949  0.15069208  0.23061752\n",
      "  1.52397635 -0.18448975 -1.08876736 -1.18478348 -0.02331324 -0.70942825\n",
      "  0.72819788  0.86041629  1.02140516  0.56453705 -1.74735187  0.35069892\n",
      "  1.54398907  0.15716882  0.33339782  0.76760463 -0.21673031 -0.93450694\n",
      "  0.30849883 -0.32614147  0.31815252 -0.67425088]\n",
      "[ 0.01581864 -0.01425455 -0.00871603 -0.00455534  0.00651855  0.03813752\n",
      "  0.00310788 -0.01560026  0.01996884 -0.03499781  0.0143725  -0.0178095\n",
      " -0.01310199 -0.03382893  0.01897174 -0.00755865  0.01592829  0.03693443\n",
      " -0.02923819  0.03252797  0.00131931  0.00615089  0.04650518 -0.02384858\n",
      "  0.02067039 -0.0147373  -0.04415022  0.02059821 -0.03460832  0.02265688\n",
      "  0.03844573  0.02502458  0.03888545  0.00633208  0.01160438 -0.00805943\n",
      "  0.00858295  0.0191369  -0.01660148 -0.00780938]\n",
      "-0.0190150277791\n",
      "0.0677753535633\n",
      "0.0244991572582\n"
     ]
    }
   ],
   "source": [
    "# so now the model is fit and we can calculate with the recommendations\n",
    "# furthermore we have acces to user and item factors\n",
    "print(wmf.user_factors[1])\n",
    "print(wmf.item_factors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the example below, were we have user 2, and items 1, 2, and 3, we can see the score we give to the different items for user 1. As we can see, the user has the highest score on item 2, so we would recommend this item to this user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0190150277791\n",
      "0.0677753535633\n",
      "0.0244991572582\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(wmf.item_factors[0],wmf.user_factors[1]))\n",
    "print(np.dot(wmf.item_factors[1],wmf.user_factors[1])) #<-- the highest score\n",
    "print(np.dot(wmf.item_factors[2],wmf.user_factors[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
